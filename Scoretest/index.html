<!DOCTYPE html>
<html>
<head>

  <link rel="stylesheet" type="text/css" href="./styles/exercise_style.css">
  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
  <script src="./scripts/exercise_scripts.js"></script>

  <title>Discussion Page Test</title>
</head>
<body>
  <!-- The core Firebase JS SDK is always required and must be listed first -->
  <!--<script src="https://www.gstatic.com/firebasejs/6.3.4/firebase-app.js"></script>-->

  <!-- TODO: Add SDKs for Firebase products that you want to use
      https://firebase.google.com/docs/web/setup#config-web-app -->

      <!--<script src="https://www.gstatic.com/firebasejs/5.10.1/firebase-auth.js"></script>
      <script src="https://www.gstatic.com/firebasejs/5.10.1/firebase-database.js"></script>

  <script>
  // Your web app's Firebase configuration
  var firebaseConfig = {
      apiKey: "AIzaSyCvn4iUm8Bq2GY0twaT0deGwZJrekJfOyA",
      authDomain: "discussion-5e4ef.firebaseapp.com",
      databaseURL: "https://discussion-5e4ef.firebaseio.com",
      projectId: "discussion-5e4ef",
      storageBucket: "discussion-5e4ef.appspot.com",
      messagingSenderId: "502504758913",
      appId: "1:502504758913:web:702d988d488a4a88"
  };
  // Initialize Firebase
  firebase.initializeApp(firebaseConfig);
</script>-->

  <div id="main-content">
    <div id="headline">Help us Understanding the Machine Learning (ML) Output</div>
    <div id="topdesc">Select text from the following list or write your own text to find out the reasoning behind the ML score</div>
    <div id="author-break"></div>
  </div>
  <br>
  <div id="headline-article-break"></div>
  <div class="article-text">
    The toxic comment in online discusssion means whether a comment is a rude, disrespectful, or unreasonable comment that is likely to make people leave a discussion. <br>
    <br>
    We are using <a href="https://www.perspectiveapi.com/" target="_blank">Google's perspectiveAPI</a> to measure the probability of a text to <b>perceived</b> as toxic in a discussion in percentage scale.
    Perspective’s scoring system was trained using hundreds of thousands of human-moderated comments to identify patterns that make a comment “toxic”. <br>
    As a user of online discussion, we want to understand how this ML model scoring the toxicity of a text and how to improve the output.
  </div>
    <!-- <div id="article-voting" class="secondary-interactions">
      <button class="response-button" onclick="buttonClicked('downvote', this);" type="button"> <img id="downvote-article-icon-1" class="button-icon" src='./resources/downvote.png'> Downvote </button>
      <button class="response-button" onclick="buttonClicked('upvote', this);" type="button"> <img id="upvote-article-icon-1" class="button-icon" src='./resources/upvote.png'> Upvote </button>
    </div> -->


  <div id="comment-section-break"></div>
  <div class="reply-out">
    <div class="comment-reply reply-in1">
      <textarea id="comment-textarea" placeholder="Type a draft comment to view the ML score" class="reply-textarea"></textarea>
    </div>
    <div> OR,
    </div>
    <div class="comment-reply reply-in1">
      <div> Select one from the exisitng comments of a discussion
      </div>
      <div class="comment-reply reply-in2">
        <span class = "forclick">They are liberal idiots who are uneducated.</span><br>
        <span class = "forclick">They're stupid, it's getting warmer, we should enjoy it while it lasts.</span><br>
        <span class = "forclick">hello</span><br>
        <span class = "forclick">hello</span><br>
        <span class = "forclick">hello</span><br>
        <span class = "forclick">hello</span><br>
        <span class = "forclick">hello</span><br>
        <span class = "forclick">hello</span><br>
      </div>
    </div>
  </div>

</body>
